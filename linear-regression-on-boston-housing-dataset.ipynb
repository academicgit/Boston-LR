{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Linear Regression on Boston Housing Dataset\n\nThis data was originally a part of UCI Machine Learning Repository and has been removed now. This data also ships with the scikit-learn library. \nThere are 506 samples and 13 feature variables in this data-set. The objective is to predict the value of prices of the house using the given features.\n\nThe description of all the features is given below:\n\n  **CRIM**: Per capita crime rate by town\n\n  **ZN**: Proportion of residential land zoned for lots over 25,000 sq. ft\n\n  **INDUS**: Proportion of non-retail business acres per town\n\n  **CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n\n  **NOX**: Nitric oxide concentration (parts per 10 million)\n\n  **RM**: Average number of rooms per dwelling\n\n  **AGE**: Proportion of owner-occupied units built prior to 1940\n\n  **DIS**: Weighted distances to five Boston employment centers\n\n  **RAD**: Index of accessibility to radial highways\n\n  **TAX**: Full-value property tax rate per $10,000\n\n  **B**: 1000(Bk - 0.63)Â², where Bk is the proportion of [people of African American descent] by town\n\n  **LSTAT**: Percentage of lower status of the population\n\n  **MEDV**: Median value of owner-occupied homes in $1000s","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-06T14:17:20.612842Z","iopub.execute_input":"2022-09-06T14:17:20.616737Z","iopub.status.idle":"2022-09-06T14:17:20.646037Z","shell.execute_reply.started":"2022-09-06T14:17:20.616563Z","shell.execute_reply":"2022-09-06T14:17:20.645207Z"}}},{"cell_type":"code","source":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:26:58.307686Z","iopub.execute_input":"2022-09-07T15:26:58.308138Z","iopub.status.idle":"2022-09-07T15:26:58.938859Z","shell.execute_reply.started":"2022-09-07T15:26:58.308103Z","shell.execute_reply":"2022-09-07T15:26:58.937901Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the Boston Housing DataSet from scikit-learn\nfrom sklearn.datasets import load_boston\n\nboston_dataset = load_boston()\n\n# boston_dataset is a dictionary\n# let's check what it contains\nboston_dataset.keys()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:28:02.752801Z","iopub.execute_input":"2022-09-07T15:28:02.754013Z","iopub.status.idle":"2022-09-07T15:28:02.900962Z","shell.execute_reply.started":"2022-09-07T15:28:02.753972Z","shell.execute_reply":"2022-09-07T15:28:02.899882Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the data into pandas dataframe\nboston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\nboston.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:29:09.318432Z","iopub.execute_input":"2022-09-07T15:29:09.318836Z","iopub.status.idle":"2022-09-07T15:29:09.352813Z","shell.execute_reply.started":"2022-09-07T15:29:09.318807Z","shell.execute_reply":"2022-09-07T15:29:09.351945Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# The target values is missing from the data.\n# Create a new column of target values and add it to dataframe\nboston['MEDV'] = boston_dataset.target","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:31:08.761152Z","iopub.execute_input":"2022-09-07T15:31:08.761586Z","iopub.status.idle":"2022-09-07T15:31:08.771634Z","shell.execute_reply.started":"2022-09-07T15:31:08.761537Z","shell.execute_reply":"2022-09-07T15:31:08.770650Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Data preprocessing\n# check for missing values in all the columns\nboston.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:31:41.419851Z","iopub.execute_input":"2022-09-07T15:31:41.420291Z","iopub.status.idle":"2022-09-07T15:31:41.431690Z","shell.execute_reply.started":"2022-09-07T15:31:41.420256Z","shell.execute_reply":"2022-09-07T15:31:41.430712Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Data Visualization\n# set the size of the figure\nsns.set(rc={'figure.figsize':(11.7,8.27)})\n\n# plot a histogram showing the distribution of the target values\nsns.histplot(boston['MEDV'], bins=30, kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:36:48.078137Z","iopub.execute_input":"2022-09-07T15:36:48.078554Z","iopub.status.idle":"2022-09-07T15:36:48.407758Z","shell.execute_reply.started":"2022-09-07T15:36:48.078519Z","shell.execute_reply":"2022-09-07T15:36:48.406618Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix\n# compute the pair wise correlation for all columns  \ncorrelation_matrix = boston.corr().round(2)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:37:28.373575Z","iopub.execute_input":"2022-09-07T15:37:28.374007Z","iopub.status.idle":"2022-09-07T15:37:28.387220Z","shell.execute_reply.started":"2022-09-07T15:37:28.373971Z","shell.execute_reply":"2022-09-07T15:37:28.386129Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# use the heatmap function from seaborn to plot the correlation matrix\n# \"annot = True\" to print the values inside the square\nsns.heatmap(data=correlation_matrix,annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:38:07.869316Z","iopub.execute_input":"2022-09-07T15:38:07.869700Z","iopub.status.idle":"2022-09-07T15:38:09.355715Z","shell.execute_reply.started":"2022-09-07T15:38:07.869670Z","shell.execute_reply":"2022-09-07T15:38:09.354519Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Observations**\n\n* From the above coorelation plot we can see that **MEDV** is strongly correlated to **LSTAT**, **RM**\n\n* **RAD** and **TAX** are stronly correlated, so we don't include this in our features together to avoid multi-colinearity","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 5))\n\nfeatures = ['LSTAT', 'RM']\ntarget = boston['MEDV']\n\nfor i, col in enumerate(features):\n    plt.subplot(1, len(features) , i+1)\n    x = boston[col]\n    y = target\n    plt.scatter(x, y, marker='o')\n    plt.title(col)\n    plt.xlabel(col)\n    plt.ylabel('MEDV')","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:43:40.652095Z","iopub.execute_input":"2022-09-07T15:43:40.652744Z","iopub.status.idle":"2022-09-07T15:43:41.196003Z","shell.execute_reply.started":"2022-09-07T15:43:40.652692Z","shell.execute_reply":"2022-09-07T15:43:41.194663Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Prepare the data for training\n\nX = pd.DataFrame(np.c_[boston['LSTAT'], boston['RM']], columns = ['LSTAT','RM'])\nY = boston['MEDV']","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:45:36.012325Z","iopub.execute_input":"2022-09-07T15:45:36.013137Z","iopub.status.idle":"2022-09-07T15:45:36.019535Z","shell.execute_reply.started":"2022-09-07T15:45:36.013098Z","shell.execute_reply":"2022-09-07T15:45:36.018424Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\n# splits the training and test data set in 80% : 20%\n# assign random_state to any value.This ensures consistency.\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:46:05.877194Z","iopub.execute_input":"2022-09-07T15:46:05.877628Z","iopub.status.idle":"2022-09-07T15:46:05.942485Z","shell.execute_reply.started":"2022-09-07T15:46:05.877590Z","shell.execute_reply":"2022-09-07T15:46:05.941213Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Train the model using sklearn LinearRegression\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nlin_model = LinearRegression()\nlin_model.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:46:27.329612Z","iopub.execute_input":"2022-09-07T15:46:27.330267Z","iopub.status.idle":"2022-09-07T15:46:27.426417Z","shell.execute_reply.started":"2022-09-07T15:46:27.330231Z","shell.execute_reply":"2022-09-07T15:46:27.425083Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## **MAE** : Mean Absolute Error\n- it represents the difference between the original and predicted values extracted by averaged the absolute difference over the data set.\n\n## **MSE** : *Mean Square Error*\n\n- MSE is a risk function that helps us determine the average squared difference between the predicted and the actual value of a feature or variable.\n\n## **RMSE** : *Root Mean Square Error*\n\n- The square root of value obtained from Mean Square Error function.Using RMSE, we can easily plot a difference between the estimated and actual values of a parameter of the model.\n\n## **R2 Score** : *Coefficient of Determination* \n- Coefficient of determination also called as R2 score is used to evaluate the performance of a linear regression model. It is the amount of the variation in the output dependent attribute which is predictable from the input independent variable(s). It is used to check how well-observed results are reproduced by the model, depending on the ratio of total deviation of results described by the model.","metadata":{}},{"cell_type":"code","source":"# model evaluation for training set\n\ny_train_predict = lin_model.predict(X_train)\nrmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\nr2 = r2_score(Y_train, y_train_predict)\n\nprint(\"The model performance for training set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))\nprint(\"\\n\")\n\n# model evaluation for testing set\n\ny_test_predict = lin_model.predict(X_test)\n# root mean square error of the model\nrmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n\n# r-squared score of the model\nr2 = r2_score(Y_test, y_test_predict)\n\nprint(\"The model performance for testing set\")\nprint(\"--------------------------------------\")\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:47:11.678576Z","iopub.execute_input":"2022-09-07T15:47:11.679022Z","iopub.status.idle":"2022-09-07T15:47:11.693022Z","shell.execute_reply.started":"2022-09-07T15:47:11.678985Z","shell.execute_reply":"2022-09-07T15:47:11.692124Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# plotting the y_test vs y_pred\n# ideally should have been a straight line\nplt.scatter(Y_test, y_test_predict)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T15:47:22.805384Z","iopub.execute_input":"2022-09-07T15:47:22.805771Z","iopub.status.idle":"2022-09-07T15:47:23.066368Z","shell.execute_reply.started":"2022-09-07T15:47:22.805740Z","shell.execute_reply":"2022-09-07T15:47:23.065488Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}